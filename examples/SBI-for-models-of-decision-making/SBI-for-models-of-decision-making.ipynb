{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import torch\n",
    "\n",
    "import sbi\n",
    "import sbibm\n",
    "from sbi.inference import SNLE\n",
    "from sbi.inference import likelihood_estimator_based_potential, MCMCPosterior\n",
    "from mnle_utils import BernoulliMN, MNLE\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"ddm_training_data_gitlfs.p\", \"rb\") as fh:\n",
    "    theta, x = pickle.load(fh).values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choices are encoded as the sign of rts\n",
    "num_simulations = 100000\n",
    "theta = theta[:num_simulations]\n",
    "x = x[:num_simulations]\n",
    "rts = abs(x)\n",
    "choices = torch.zeros_like(x)\n",
    "choices[x > 0] = 1\n",
    "\n",
    "theta_and_choices = torch.hstack((theta, choices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "plt.hist(x.numpy(), bins=50, density=True)\n",
    "plt.xlabel(\"reaction time [s] (sign encodes choice)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_choice_net(batch_theta, batch_choices, num_choices=2, z_score_theta=False, hidden_features: int=10, hidden_layers: int=2):\n",
    "    \n",
    "    dim_parameters = batch_theta[0].numel()\n",
    "    num_output = num_choices\n",
    "    \n",
    "    assert num_choices == 2, \"Not implemented for more than two choices.\"\n",
    "    \n",
    "    choice_net = BernoulliMN(n_input=dim_parameters, \n",
    "                             n_output=1, \n",
    "                             n_hidden_layers=hidden_layers, \n",
    "                             n_hidden_units=hidden_features)\n",
    "    \n",
    "    if z_score_theta:\n",
    "        choice_net = nn.Sequential(standardizing_net(batch_y), choice_net)\n",
    "    \n",
    "    return choice_net\n",
    "\n",
    "choice_net_builder = partial(build_choice_net, z_score_theta=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_rt_flow(batch_theta, batch_x, \n",
    "                  num_transforms=2, \n",
    "                  hidden_features=10, \n",
    "                  num_bins=5, \n",
    "                  tail_bound=10.0, \n",
    "                 **kwargs\n",
    "                 ):\n",
    "\n",
    "    return sbi.neural_nets.flow.build_nsf(batch_x=batch_x, batch_y=batch_theta, \n",
    "                                          num_transforms=num_transforms, \n",
    "                                          hidden_features=hidden_features, \n",
    "                                          num_bins=num_bins, \n",
    "                                          tail_bound=tail_bound,\n",
    "                                          **kwargs\n",
    "                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_trainer = SNLE(density_estimator=build_rt_flow)\n",
    "\n",
    "rt_flow = rt_trainer.append_simulations(theta_and_choices, rts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_flow = rt_trainer.train(max_num_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = SNLE(density_estimator=choice_net_builder, )\n",
    "choice_estimator = trainer.append_simulations(theta, choices).train(max_num_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnle = MNLE(choice_estimator, rt_flow, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = sbibm.get_task(\"ddm\").get_prior_dist()\n",
    "num_trials = 100\n",
    "tho = prior.sample((1,))\n",
    "x_o = mnle.sample(num_trials, tho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "potential_fn, parameter_transform = likelihood_estimator_based_potential(mnle, prior, x_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_chains = 1\n",
    "%timeit potential_fn(prior.sample((num_chains,))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior = MCMCPosterior(potential_fn, proposal=prior, theta_transform=parameter_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_samples = posterior.sample((10,), method=\"slice_np\", thin=1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
